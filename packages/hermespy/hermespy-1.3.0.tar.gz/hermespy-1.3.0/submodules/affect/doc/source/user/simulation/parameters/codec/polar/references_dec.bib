@Article{Arikan2009,
  author   = {E. Arikan},
  title    = {Channel Polarization: A Method for Constructing Capacity-Achieving Codes for Symmetric Binary-Input Memoryless Channels},
  journal  = {IEEE Transactions on Information Theory (TIT)},
  year     = {2009},
  volume   = {55},
  number   = {7},
  pages    = {3051--3073},
  month    = jul,
  issn     = {0018-9448},
  abstract = {A method is proposed, called channel polarization, to construct code sequences that achieve the symmetric capacity I(W) of any given binary-input discrete memoryless channel (B-DMC) W. The symmetric capacity is the highest rate achievable subject to using the input letters of the channel with equal probability. Channel polarization refers to the fact that it is possible to synthesize, out of N independent copies of a given B-DMC W, a second set of N binary-input channels {WN(i)1 les i les N} such that, as N becomes large, the fraction of indices i for which I(WN(i)) is near 1 approaches I(W) and the fraction for which I(WN(i)) is near 0 approaches 1-I(W). The polarized channels {WN(i)} are well-conditioned for channel coding: one need only send data at rate 1 through those with capacity near 1 and at rate 0 through the remaining. Codes constructed on the basis of this idea are called polar codes. The paper proves that, given any B-DMC W with I(W) $>$ 0 and any target rate R$<$ I(W) there exists a sequence of polar codes {Cfrn;nges1} such that Cfrn has block-length N=2n , rate ges R, and probability of block error under successive cancellation decoding bounded as Pe(N,R) les O(N-1/4) independently of the code rate. This performance is achievable by encoders and decoders with complexity O(N logN) for each.},
  doi      = {10.1109/TIT.2009.2021379},
  file     = {:pdf/Arikan2009 - Channel Polarization\: A Method for Constructing Capacity-Achieving Codes for Symmetric Binary-Input Memoryless Channels.pdf:PDF},
  groups   = {Polar Codes},
  keywords = {binary codes, channel capacity, channel coding, decoding, memoryless systems, probability, channel capacity, channel coding, channel polarization, code sequence, polar codes, probability, successive cancellation decoding algorithm, symmetric binary-input memoryless channel, Capacity planning, Channel capacity, Channel coding, Codes, Councils, Decoding, Information theory, Memoryless systems, Noise cancellation, Polarization, Capacity-achieving codes, Plotkin construction, Reed-- Muller (RM) codes, channel capacity, channel polarization, polar codes, successive cancellation decoding},
}

@Article{Fayyaz2014,
  author   = {U. U. Fayyaz and J. R. Barry},
  title    = {Low-Complexity Soft-Output Decoding of Polar Codes},
  journal  = {IEEE Journal on Selected Areas in Communications (JSAC)},
  year     = {2014},
  volume   = {32},
  number   = {5},
  pages    = {958--966},
  month    = may,
  issn     = {0733-8716},
  abstract = {The state-of-the-art soft-output decoder for polar codes is a message-passing algorithm based on belief propagation, which performs well at the cost of high processing and storage requirements. In this paper, we propose a low-complexity alternative for soft-output decoding of polar codes that offers better performance but with significantly reduced processing and storage requirements. In particular we show that the complexity of the proposed decoder is only 4\% of the total complexity of the belief propagation decoder for a rate one-half polar code of dimension 4096 in the dicode channel, while achieving comparable error-rate performance. Furthermore, we show that the proposed decoder requires about 39\% of the memory required by the belief propagation decoder for a block length of 32768.},
  doi      = {10.1109/JSAC.2014.140515},
  file     = {:pdf/Fayyaz2014 - Low-Complexity Soft-Output Decoding of Polar Codes.pdf:PDF},
  groups   = {Factor Graphs, Polar Codes},
  keywords = {decoding, error statistics, message passing, belief propagation decoder, dicode channel, error rate performance, low-complexity soft-output decoding, message passing algorithm, polar codes, Belief propagation, Complexity theory, Decoding, Iterative decoding, Memory management, Receivers, Polar codes, soft-output decoding, turbo equalization, SCAN},
}

@InProceedings{Tal2011,
  author    = {I. Tal and A. Vardy},
  title     = {List Decoding of Polar Codes},
  booktitle = {International Symposium on Information Theory (ISIT)},
  year      = {2011},
  pages     = {1--5},
  month     = jul,
  publisher = {IEEE},
  abstract  = {We describe a successive-cancellation list decoder for polar codes, which is a generalization of the classic successive-cancellation decoder of Arikan. In the proposed list decoder, up to L decoding paths are considered concurrently at each decoding stage. Simulation results show that the resulting performance is very close to that of a maximum-likelihood decoder, even for moderate values of L. Thus it appears that the proposed list decoder bridges the gap between successive-cancellation and maximum-likelihood decoding of polar codes. The specific list-decoding algorithm that achieves this performance doubles the number of decoding paths at each decoding step, and then uses a pruning procedure to discard all but the L {\textquotedblleft}best{\textquotedblright} paths. In order to implement this algorithm, we introduce a natural pruning criterion that can be easily evaluated. Nevertheless, straightforward implementation still requires O(L $\cdot$ n\textsuperscript{2}) time, which is in stark contrast with the O(n log n) complexity of the original successive-cancellation decoder. We utilize the structure of polar codes to overcome this problem. Specifically, we devise an efficient, numerically stable, implementation taking only O(L $\cdot$ n log n) time and O(L $\cdot$ n) space.},
  doi       = {10.1109/ISIT.2011.6033904},
  file      = {:pdf/Tal2011 - List Decoding of Polar Codes.pdf:PDF},
  groups    = {Polar Codes},
  issn      = {2157-8095},
  keywords  = {maximum likelihood decoding, Arikan, decoding paths, maximum likelihood decoder, polar codes, successive-cancellation list decoder, Arrays, Complexity theory, Equations, Error analysis, Mathematical model, Maximum likelihood decoding},
}

@Article{Li2012,
  author   = {B. Li and H. Shen and D. Tse},
  title    = {An Adaptive Successive Cancellation List Decoder for Polar Codes with Cyclic Redundancy Check},
  journal  = {IEEE Communications Letters (COMML)},
  year     = {2012},
  volume   = {16},
  number   = {12},
  pages    = {2044--2047},
  month    = dec,
  issn     = {1089-7798},
  abstract = {In this letter, we propose an adaptive SC (Successive Cancellation)-List decoder for polar codes with CRC. This adaptive SC-List decoder iteratively increases the list size until at least one survival path can pass CRC. Simulation shows that the adaptive SC-List decoder provides significant complexity reduction. We also demonstrate that polar code (2048, 1024) with 24-bit CRC decoded by our proposed adaptive SC-List decoder with very large maximum list size can achieve a frame error rate FER $\leq$ 10\textsuperscript{-3}{-3} at E\textsubscript{b}/N\textsubscript{o} = 1.1dB, which is about 0.25dB from the information theoretic limit at this block length.},
  doi      = {10.1109/LCOMM.2012.111612.121898},
  file     = {:pdf/Li2012 - An Adaptive Successive Cancellation List Decoder for Polar Codes with Cyclic Redundancy Check.pdf:PDF},
  groups   = {Polar Codes},
  keywords = {adaptive codes, cyclic redundancy check codes, decoding, CRC code, FER, adaptive SC list decoder, adaptive successive cancellation list decoder, cyclic redundancy check codes, frame error rate, information theoretic limit, polar codes, word length 24 bit, Complexity theory, Cyclic redundancy check, Error analysis, Iterative decoding, Maximum likelihood decoding, Signal to noise ratio, Polar codes, list decoder},
}

@Article{Leonardon2017,
  author        = {M. L{\'{e}}onardon and A. Cassagne and C. Leroux and C. J{\'{e}}go and L.-P. Hamelin and Y. Savaria},
  title         = {Fast and Flexible Software Polar List Decoders},
  journal       = {CoRR},
  volume        = {abs/1710.08314},
  year          = {2017},
  url           = {http://arxiv.org/abs/1710.08314},
  archivePrefix = {arXiv},
  eprint        = {1710.08314},
  timestamp     = {Mon, 13 Aug 2018 16:46:27 +0200},
  biburl        = {https://dblp.org/rec/bib/journals/corr/abs-1710-08314},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@Article{LeGal2015a,
  author   = {B. {Le Gal} and C. Leroux and C. J\'ego},
  title    = {Multi-{G}b/s Software Decoding of Polar Codes},
  journal  = {IEEE Transactions on Signal Processing (TSP)},
  year     = {2015},
  volume   = {63},
  number   = {2},
  pages    = {349--359},
  month    = jan,
  issn     = {1053-587X},
  abstract = {This paper presents an optimized software implementation of a Successive Cancellation (SC) decoder for polar codes. Despite the strong data dependencies in SC decoding, a highly parallel software polar decoder is devised for x86 processor target. A high level of performance is achieved by exploiting the parallelism inherent in today's processor architectures (SIMD, multicore, etc.). Some optimizations that were originally thought for hardware implementation (memory reduction techniques and algorithmic simplifications) were also applied to enhance the throughput of the software implementation. Finally, some low level optimizations such as explicit assembly description or data packing are used to improve the throughput even more. The resulting decoder description is implemented on different x86 processor targets. An analysis of the decoder in terms of latency and throughput is proposed. The influence of several parameters on the throughput and the latency is investigated: the selected target, the code rate, the code length, the SIMD mode (SSE/AVX), the multithreading mode, etc. The energy per decoded bit is also estimated. The proposed software decoder compares favorably with state of the art software polar decoders. Extensive experimentations demonstrate that the proposed software polar decoder exceeds 1 Gb/s for code lengths N $\leq$ 2\textsuperscript{17} on a single core and reaches multi-Gb/s throughputs when using four cores in parallel in AVX mode.},
  doi      = {10.1109/TSP.2014.2371781},
  file     = {:pdf/LeGal2015a - Multi-Gbps Software Decoding of Polar Codes.pdf:PDF},
  groups   = {Polar Codes, Software Decoders, HoF Polar - SC, AFF3CT},
  keywords = {decoding, optimisation, AVX mode, SC decoder, SIMD mode, algorithmic simplifications, code length, code rate, data packing, energy per decoded bit, explicit assembly description, low level optimizations, memory reduction techniques, multiGb/s software decoding, multithreading mode, parallel software polar decoder, polar codes, processor architectures, selected target, software polar decoders, successive cancellation decoder, x86 processor target, Decoding, Optimization, Signal processing algorithms, Software, Systematics, Throughput, Vectors, Polar codes, SIMD, software optimizations, successive cancellation decoding, x86 processor},
}

@InProceedings{Cassagne2015c,
  author    = {A. Cassagne and B. {Le Gal} and C. Leroux and O. Aumage and D. Barthou},
  title     = {An Efficient, Portable and Generic Library for Successive Cancellation Decoding of Polar Codes},
  booktitle = {International Workshop on Languages and Compilers for Parallel Computing (LCPC)},
  year      = {2015},
  month     = sep,
  publisher = {Springer},
  abstract  = {Error Correction Code decoding algorithms for consumer products such as Internet of Things (IoT) devices are usually implemented as dedicated hardware circuits. As processors are becoming increasingly powerful and energy efficient, there is now a strong desire to perform this processing in software to reduce production costs and time to market. The recently introduced family of Successive Cancellation decoders for Polar codes has been shown in several research works to efficiently leverage the ubiquitous SIMD units in modern CPUs, while offering strong potentials for a wide range of optimizations. The P-EDGE environment introduced in this paper, combines a specialized skeleton generator and a building blocks library routines to provide a generic, extensible Polar code exploration workbench. It enables ECC code designers to easily experiments with combinations of existing and new optimizations, while delivering performance close to state-of-art decoders.},
  date      = {2015-11-01},
  doi       = {10.1007/978-3-319-29778-1_19},
  file      = {:pdf/Cassagne2015c - An Efficient, Portable and Generic Library for Successive Cancellation Decoding of Polar Codes.pdf:PDF;:pdf/Cassagne2015c - An Efficient, Portable and Generic Library for Successive Cancellation Decoding of Polar Codes [slides].pdf:PDF;:pdf/Cassagne2015c - An Efficient, Portable and Generic Library for Successive Cancellation Decoding of Polar Codes [poster].pdf:PDF},
  groups    = {Polar Codes, Software Decoders, HoF Polar - SC, AFF3CT},
  journal   = {Languages and Compilers for Parallel Computing},
}

@InProceedings{Cassagne2016b,
  author    = {A. Cassagne and O. Aumage and C. Leroux and D. Barthou and B. {Le Gal}},
  title     = {Energy Consumption Analysis of Software Polar Decoders on Low Power Processors},
  booktitle = {European Signal Processing Conference (EUSIPCO)},
  year      = {2016},
  pages     = {642--646},
  month     = aug,
  publisher = {IEEE},
  abstract  = {This paper presents a new dynamic and fully generic implementation of a Successive Cancellation (SC) decoder (multi-precision support and intra-/inter-frame strategy support). This fully generic SC decoder is used to perform comparisons of the different configurations in terms of throughput, latency and energy consumption. A special emphasis is given on the energy consumption on low power embedded processors for software defined radio (SDR) systems. A N=4096 code length, rate 1/2 software SC decoder consumes only 14 nJ per bit on an ARM Cortex-A57 core, while achieving 65 Mbps. Some design guidelines are given in order to adapt the configuration to the application context.},
  doi       = {10.1109/EUSIPCO.2016.7760327},
  file      = {:pdf/Cassagne2016b - Energy Consumption Analysis of Software Polar Decoders on Low Power Processors.pdf:PDF;:pdf/Cassagne2016b - Energy Consumption Analysis of Software Polar Decoders on Low Power Processors [poster].pdf:PDF},
  groups    = {Polar Codes, Software Decoders, HoF Polar - SC, AFF3CT},
  keywords  = {decoding, energy consumption, software radio, telecommunication power management, ARM Cortex-A57, SC decoder implementation, SDR system, low power embedded processor, software defined radio system, software polar decoder energy consumption analysis, successive cancellation decoder implementation, Bit error rate, Decoding, Encoding, Energy consumption, Program processors, Throughput},
}

@Article{Sarkis2014a,
  author   = {G. Sarkis and P. Giard and A. Vardy and C. Thibeault and W. J. Gross},
  title    = {Fast Polar Decoders: Algorithm and Implementation},
  journal  = {IEEE Journal on Selected Areas in Communications (JSAC)},
  year     = {2014},
  volume   = {32},
  number   = {5},
  pages    = {946--957},
  month    = may,
  issn     = {0733-8716},
  abstract = {Polar codes provably achieve the symmetric capacity of a memoryless channel while having an explicit construction. The adoption of polar codes however, has been hampered by the low throughput of their decoding algorithm. This work aims to increase the throughput of polar decoding hardware by an order of magnitude relative to successive-cancellation decoders and is more than 8 times faster than the current fastest polar decoder. We present an algorithm, architecture, and FPGA implementation of a flexible, gigabit-per-second polar decoder.},
  doi      = {10.1109/JSAC.2014.140514},
  file     = {:pdf/Sarkis2014a - Fast Polar Decoders\: Algorithm and Implementation.pdf:PDF;},
  groups   = {Polar Codes, Hardware Decoders},
  keywords = {block codes, decoding, error correction codes, field programmable gate arrays, linear codes, FPGA implementation, fast polar decoders, flexible polar decoder, gigabit-per-second polar decoder, polar codes, polar decoding hardware throughput, successive-cancellation decoders, symmetric memoryless channel capacity, Complexity theory, Maximum likelihood decoding, Parity check codes, Reliability, Systematics, Throughput, polar codes, storage systems, successive-cancellation decoding, node, nodes, spc, rep},
}

@InProceedings{Afisiadis2014,
  author    = {O. Afisiadis and A. Balatsoukas-Stimming and A. Burg},
  title     = {A Low-Complexity Improved Successive Cancellation Decoder for Polar Codes},
  booktitle = {Asilomar Conference on Signals, Systems, and Computers (ACSSC)},
  year      = {2014},
  pages     = {2116--2120},
  month     = nov,
  publisher = {IEEE},
  abstract  = {Under successive cancellation (SC) decoding, polar codes are inferior to other codes of similar blocklength in terms of frame error rate. While more sophisticated decoding algorithms such as list- or stack-decoding partially mitigate this performance loss, they suffer from an increase in complexity. In this paper, we describe a new flavor of the SC decoder, called the SC flip decoder. Our algorithm preserves the low memory requirements of the basic SC decoder and adjusts the required decoding effort to the signal quality. In the waterfall region, its average computational complexity is almost as low as that of the SC decoder.},
  doi       = {10.1109/ACSSC.2014.7094848},
  file      = {:pdf/Afisiadis2014 - A Low-Complexity Improved Successive Cancellation Decoder for Polar Codes.pdf:PDF},
  groups    = {Polar Codes},
  keywords  = {computational complexity, decoding, error statistics, signal processing, average computational complexity, frame error rate, low-complexity improved SC flip decoder, polar codes, signal quality, successive cancellation decoding, Computational complexity, Decoding, Error analysis, Memory management, Signal to noise ratio, SCFlip},
}