@Article{Bose1960,
  author   = {R.C. Bose and D.K. Ray-Chaudhuri},
  title    = {On a Class of Error Correcting Binary Group Codes},
  journal  = {Springer Information and Control},
  year     = {1960},
  volume   = {3},
  number   = {1},
  pages    = {68 - 79},
  issn     = {0019-9958},
  abstract = {A general method of constructing error correcting binary group codes is obtained. A binary group code with n places, k of which are information places is called an (n,k) code. An explicit method of constructing t-error correcting (n,k) codes is given for n = 2m−1 and k = 2m−1−R(m,t) ≧ 2m−1−mt where R(m,t) is a function of m and t which cannot exceed mt. An example is worked out to illustrate the method of construction.},
  doi      = {10.1016/S0019-9958(60)90287-4},
  groups   = {Error-Correcting Codes (ECC)},
  keywords = {BCH},
}

@InProceedings{Divsalar1998,
  author    = {D. Divsalar and H. Jin, and R. J. McEliece},
  title     = {Coding Theorems for "Turbo-like" Codes},
  booktitle = {Allerton Conference on Communication, Control and Computing},
  year      = {1998},
  pages     = {201-210},
  month     = sep,
  abstract  = {In this paper we discuss AWGN coding theorems for ensembles of coding systems which are built from fixed convolutional codes interconnected with random interleavers.  We call these systems “turbo-like” codes and they include as special cases both the classical turbo codes [1,2,3] and the serial concatentation of interleaved convolutional codes [4]. We offer a general conjecture about the behavior of the ensemble (maximum-likelihood decoder) word error probability as the word length approches infinity.  We prove this conjecture for a simple class of rate 1/q serially concatenated codes where the outer code is a q-fold repetition code and the inner code is a rate 1 convolutional code with transfer function 1 / (1 + D). We believe this represents the first rigorous proof of a coding theorem for turbo-like codes.},
  file      = {:pdf/Divsalar1998 - Coding Theorems for Turbo-like Codes.pdf:PDF},
  groups    = {Error-Correcting Codes (ECC)},
  keywords  = {Repeat and Accumulate, RA},
  url       = {https://pdfs.semanticscholar.org/b5cc/c94d4f9ea6df991190f17359ddd7ac47f005.pdf},
}

@Article{Reed1960,
  author   = {I. Reed and G. Solomon},
  title    = {Polynomial Codes Over Certain Finite Fields},
  journal  = {Journal of the Society for Industrial and Applied Mathematics},
  year     = {1960},
  volume   = {8},
  number   = {2},
  pages    = {300-304},
  doi      = {10.1137/0108018},
  file     = {:pdf/Reed1960 - Polynomial Codes Over Certain Finite Fields.pdf:PDF},
  groups   = {Error-Correcting Codes (ECC)},
  keywords = {Reed-Solomon, RS},
}

@InProceedings{MacKay1995,
  author    = {D. J. C. MacKay and R. M. Neal},
  title     = {Good Codes Based on Very Sparse Matrices},
  booktitle = {IMA International Conference on Cryptography and Coding (IMA-CCC)},
  year      = {1995},
  pages     = {100--111},
  address   = {UK},
  month     = dec,
  publisher = {Springer},
  doi       = {10.1007/3-540-60693-9_13},
  file      = {:pdf/MacKay1995 - Good Codes Based on Very Sparse Matrices.pdf:PDF},
  groups    = {LDPC Codes},
  isbn      = {978-3-540-49280-1},
}

@Misc{Gallager1963,
  author = {R. G. Gallager},
  title  = {Low-Density Parity-Check Codes},
  year   = {1963},
  file   = {:pdf/Gallager1963 - Low-Density Parity-Check Code.pdf:PDF},
  groups = {LDPC Codes},
  url    = {http://web.mit.edu/gallager/www/pages/ldpc.pdf},
}

@Book{Ryan2009,
  title     = {Channel codes: classical and modern},
  publisher = {Cambridge University Press},
  year      = {2009},
  author    = {W. Ryan and S. Lin},
  month     = sep,
  isbn      = {978-0-511-64182-4},
  abstract  = {Channel coding lies at the heart of digital communication and data storage, and this detailed introduction describes the core theory as well as decoding algorithms, implementation details, and performance analyses.
Professors Ryan and Lin, known for the clarity of their writing, provide the latest information on modern channel codes, including turbo and low-density parity-check (LDPC) codes. They also present detailed coverage of BCH codes, Reed–Solomon codes, convolutional codes, finite-geometry codes, and product codes, providing a one-stop resource for both classical and modern coding techniques.
The opening chapters begin with basic theory to introduce newcomers to the subject, assuming no prior knowledge in the field of channel coding. Subsequent chapters cover the encoding and decoding of the most widely used codes and extend to advanced topics such as code ensemble performance analyses and algebraic code design. Numerous varied and stimulating end-of-chapter problems, 250 in total,
are also included to test and enhance learning, making this an essential resource for students and practitioners alike.},
  file      = {:pdf/Ryan2009 - Channel codes\: classical and modern.pdf:PDF},
  groups    = {Error-Correcting Codes (ECC)},
  url       = {http://www.cambridge.org/9780521848688},
}

@InProceedings{Berrou1993,
  author    = {C. Berrou and A. Glavieux and P. Thitimajshima},
  title     = {Near {Shannon} Limit Error-Correcting Coding and Decoding: Turbo-Codes},
  booktitle = {International Conference on Communications (ICC)},
  year      = {1993},
  volume    = {2},
  pages     = {1064--1070 vol.2},
  month     = may,
  publisher = {IEEE},
  abstract  = {A new class of convolutional codes called turbo-codes, whose performances in terms of bit error rate (BER) are close to the Shannon limit, is discussed. The turbo-code encoder is built using a parallel concatenation of two recursive systematic convolutional codes, and the associated decoder, using a feedback decoding rule, is implemented as P pipelined identical elementary decoders},
  doi       = {10.1109/ICC.1993.397441},
  file      = {:pdf/Berrou1993 - Near Shannon Limit Error-Correcting Coding and Decoding\: Turbo-Codes.pdf:PDF},
  groups    = {Turbo Codes},
  keywords  = {codecs, concatenated codes, convolutional codes, decoding, error correction codes, error statistics, feedback, pipeline processing, Shannon limit, bit error rate, decoder, encoder, feedback decoding rule, parallel concatenation, pipelined identical elementary decoders, recursive systematic convolutional codes, turbo-codes, Bit error rate, Convolutional codes, Decoding, Digital communication, Digital integrated circuits, Equations, Europe, Feedback, Laboratories, Turbo codes},
}

@Article{Arikan2009,
  author   = {E. Arikan},
  title    = {Channel Polarization: A Method for Constructing Capacity-Achieving Codes for Symmetric Binary-Input Memoryless Channels},
  journal  = {IEEE Transactions on Information Theory (TIT)},
  year     = {2009},
  volume   = {55},
  number   = {7},
  pages    = {3051--3073},
  month    = jul,
  issn     = {0018-9448},
  abstract = {A method is proposed, called channel polarization, to construct code sequences that achieve the symmetric capacity I(W) of any given binary-input discrete memoryless channel (B-DMC) W. The symmetric capacity is the highest rate achievable subject to using the input letters of the channel with equal probability. Channel polarization refers to the fact that it is possible to synthesize, out of N independent copies of a given B-DMC W, a second set of N binary-input channels {WN(i)1 les i les N} such that, as N becomes large, the fraction of indices i for which I(WN(i)) is near 1 approaches I(W) and the fraction for which I(WN(i)) is near 0 approaches 1-I(W). The polarized channels {WN(i)} are well-conditioned for channel coding: one need only send data at rate 1 through those with capacity near 1 and at rate 0 through the remaining. Codes constructed on the basis of this idea are called polar codes. The paper proves that, given any B-DMC W with I(W) $>$ 0 and any target rate R$<$ I(W) there exists a sequence of polar codes {Cfrn;nges1} such that Cfrn has block-length N=2n , rate ges R, and probability of block error under successive cancellation decoding bounded as Pe(N,R) les O(N-1/4) independently of the code rate. This performance is achievable by encoders and decoders with complexity O(N logN) for each.},
  doi      = {10.1109/TIT.2009.2021379},
  file     = {:pdf/Arikan2009 - Channel Polarization\: A Method for Constructing Capacity-Achieving Codes for Symmetric Binary-Input Memoryless Channels.pdf:PDF},
  groups   = {Polar Codes},
  keywords = {binary codes, channel capacity, channel coding, decoding, memoryless systems, probability, channel capacity, channel coding, channel polarization, code sequence, polar codes, probability, successive cancellation decoding algorithm, symmetric binary-input memoryless channel, Capacity planning, Channel capacity, Channel coding, Codes, Councils, Decoding, Information theory, Memoryless systems, Noise cancellation, Polarization, Capacity-achieving codes, Plotkin construction, Reed-- Muller (RM) codes, channel capacity, channel polarization, polar codes, successive cancellation decoding},
}

@InProceedings{Benammar2017,
  author    = {M. Benammar and V. Bioglio and F. Gabry and I. Land},
  title     = {Multi-Kernel Polar Codes: Proof of Polarization and Error Exponents},
  booktitle = {Information Theory Workshop (ITW)},
  year      = {2017},
  pages     = {101--105},
  month     = nov,
  publisher = {IEEE},
  abstract  = {In this paper, we investigate a novel family of polar codes based on multi-kernel constructions, proving that this construction actually polarizes. To this end, we derive a new and more general proof of polarization, which gives sufficient conditions for kernels to polarize. Finally, we derive the convergence rate of the multi-kernel construction and relate it to the convergence rate of each of the constituent kernels.},
  doi       = {10.1109/ITW.2017.8277949},
  file      = {:pdf/Benammar2017 - Multi-Kernel Polar Codes\: Proof of Polarization and Error Exponents.pdf:PDF},
  groups    = {Polar Codes},
  keywords  = {convergence, theorem proving, proof of polarization, constituent kernels, convergence rate, multikernel construction, error exponents, multikernel polar codes, Kernel, Convergence, Reliability, Random variables, Decoding, Conferences, multi kernel, multi-kernel},
}