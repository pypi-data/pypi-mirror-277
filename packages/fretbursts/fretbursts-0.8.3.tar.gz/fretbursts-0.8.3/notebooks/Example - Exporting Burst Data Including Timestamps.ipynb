{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "input_collapsed": false
   },
   "source": [
    "# Exporting Burst Data\n",
    "\n",
    "*This notebook is part of a [tutorial series](https://github.com/OpenSMFS/FRETBursts_notebooks) for the [FRETBursts](http://opensmfs.github.io/FRETBursts/) burst analysis software.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In this notebook, show a few example of how to export [FRETBursts](http://opensmfs.github.io/FRETBursts/) \n",
    "> burst data to a file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Please <b>cite</b> FRETBursts in publications or presentations!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the software"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading **`FRETBursts`**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fretbursts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns = init_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading the data file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full list of smFRET measurements used in the [FRETBursts tutorials](https://github.com/OpenSMFS/FRETBursts_notebooks) \n",
    "can be found on [Figshare](http://dx.doi.org/10.6084/m9.figshare.1456362).\n",
    "\n",
    "This is the file we will download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://files.figshare.com/2182601/0023uLRpitc_NTP_20dT_0.5GndCl.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "You can change the <code>url</code> variable above to download your own data file.\n",
    "This is useful if you are executing FRETBursts online and you want to use\n",
    "your own data file. See \n",
    "<a href=\"1. First Steps - Start here if new to Jupyter Notebooks.ipynb\">First Steps</a>.\n",
    "</div>\n",
    "\n",
    "Here, we download the data file and put it in a folder named `data`, \n",
    "inside the notebook folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file(url, save_dir='./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE**: If you modified the `url` variable providing an invalid URL\n",
    "> the previous command will fail. In this case, edit the cell containing \n",
    "> the `url` and re-try the download."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can directly define the file name to be loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./data/0023uLRpitc_NTP_20dT_0.5GndCl.hdf5\"\n",
    "filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the file exists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.isfile(filename):\n",
    "    print(\"Perfect, file found!\")\n",
    "else:\n",
    "    print(\"Sorry, file:\\n%s not found\" % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = loader.photon_hdf5(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Î¼s-ALEX parameters\n",
    "\n",
    "At this point, timestamps and detectors numbers are contained in the `ph_times_t` and `det_t` attributes of `d`. Let's print them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.ph_times_t, d.det_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define some ALEX parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.add(det_donor_accept = (0, 1), \n",
    "      alex_period = 4000,\n",
    "      offset = 700,\n",
    "      D_ON = (2180, 3900), \n",
    "      A_ON = (200, 1800))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the parameters are:\n",
    "\n",
    "- `det_donor_accept`: donor and acceptor channels\n",
    "- `alex_period`: length of excitation period (in timestamps units)\n",
    "- `D_ON` and `A_ON`: donor and acceptor excitation windows\n",
    "- `offset`: the offset between the start of alternation and start of timestamping \n",
    "  (see also [Definition of alternation periods](http://photon-hdf5.readthedocs.org/en/latest/phdata.html#definition-of-alternation-periods)).\n",
    "\n",
    "To check that the above parameters are correct, we need to plot the histogram of timestamps (modulo the alternation period) and superimpose the two excitation period definitions to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpl.plot_alternation_hist(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the previous alternation histogram looks correct, \n",
    "the corresponding definitions of the excitation periods can be applied to the data using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.alex_apply_period(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the previous histogram does not look right, the parameters in the `d.add(...)` cell can be modified and checked by running the histogram plot cell until everything looks fine. Don't forget to apply the \n",
    "parameters with `loader.usalex_apply_period(d)` as a last step.\n",
    "\n",
    "> **NOTE:** After applying the ALEX parameters a new array of \n",
    "> timestamps containing only photons inside the excitation periods \n",
    "> is created (name `d.ph_times_m`). To save memory, by default, \n",
    "> the old timestamps array (`d.ph_times_t`) is deleted. Therefore, \n",
    "> in the following, when we talk about all-photon selection we always \n",
    "> refer to all photons inside both excitation periods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background and burst search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.calc_bg(bg.exp_fit, time_s=30, tail_min_us='auto', F_bg=1.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.burst_search(L=10, m=10, F=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we filter the bursts to avoid creating big files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = d.select_bursts(select_bursts.size, th1=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Burst Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By burst-data we mean all the scalar burst parameters, e.g. size, duration, background, etc...\n",
    "\n",
    "We can easily get a table (a pandas DataFrame) with all the burst data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bursts = bext.burst_data(ds, include_bg=True, include_ph_index=True)\n",
    "bursts.head(5)  # display first 5 bursts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the DataFrame, saving it to disk in CSV format is trivial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bursts.to_csv('%s_burst_data.csv' % filename.replace('.hdf5', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Bursts Timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A convenient way to deal with timestamps (and nanotimes if available) \n",
    "of photons inside bursts is exporting them as a DataFrame.\n",
    "The function `bext.burst_photons` ([documentation](http://fretbursts.readthedocs.io/en/latest/plugins.html#fretbursts.burstlib_ext.burst_photons)) \n",
    "will export this \"photon data\"\n",
    "with one row per photon. The columns are `timestamp` and, if available,\n",
    "`nanotime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burstph = bext.burst_photons(ds)\n",
    "burstph.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This DataFrame has a two-level index (the first two columns): one is \n",
    "the burst number and the other is the photon number within each burst.\n",
    "The photon number starts at 0 for the first photon of each burst.\n",
    "\n",
    "As with any DataFrame, saving to disk is trivial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burstph.to_csv('photon_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the data back use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burstph2 = pd.read_csv('photon_data.csv', index_col=(0, 1))\n",
    "burstph2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the data we read is the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(burstph2 == burstph).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the timestamps DataFrame\n",
    "\n",
    "Operations on the photon-data DataFrame are very simple.\n",
    "\n",
    "### Transform the timestamps\n",
    "\n",
    "An example of a transformation is rescaling to get timestamps in seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burstph['times_s'] = burstph.timestamp * d.clk_p\n",
    "burstph.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute burst-wise quantities\n",
    "\n",
    "We can compute burst-wise quantities in one step without looping \n",
    "using standard [pandas group-by/apply](https://pandas.pydata.org/pandas-docs/stable/groupby.html) operations.\n",
    "\n",
    "To do that, we group rows (photons) by `'burst'` and compute an arbitrary\n",
    "function on each burst (for example the mean time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burstph.groupby('burst')['times_s'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another example of exporting bursts timestamps\n",
    "\n",
    "> **NOTE**: This section is provided as an example. Exporting timestamps in this way\n",
    "> is not recommended. Use the approach in the previous section instead.\n",
    "> The example here is an old example reported for educational purposes only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting timestamps and other photon-data for each bursts is a little trickier\n",
    "because the data is less uniform (i.e. each burst has a different number of photons).\n",
    "In the following example, we will save a `csv` file with variable-length columns.\n",
    "Each burst is represented by to lines: one line for timestamps and one line for the\n",
    "photon-stream (excitation/emission period) the timestamps belongs to.\n",
    "\n",
    "Let's start by creating an array of photon streams containing\n",
    "one of the values 0, 1, 2 or  3  for each timestamp.\n",
    "These values will correspond to the DexDem, DexAem, AexDem, AemAem\n",
    "photon streams respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.A_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{0: DexDem, 1:DexAem, 2: AexDem, 3: AemAem}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds.A_ex[0].view('int8') << 1) + ds.A_em[0].view('int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define an header documenting the file format. We will also include the \n",
    "filename of the measurement. \n",
    "\n",
    "This is just an example including nanotimes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = \"\"\"\\\n",
    "# BPH2CSV: %s\n",
    "# Lines per burst: 3\n",
    "# - timestamps (int64): in 12.5 ns units\n",
    "# - nanotimes (int16): in raw TCSPC unit (3.3ps)\n",
    "# - stream (uint8): the photon stream according to the mapping {0: DexDem, 1: DexAem, 2: AexDem, 3: AemAem}\n",
    "\"\"\" % filename\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is header we are going to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = \"\"\"\\\n",
    "# BPH2CSV: %s\n",
    "# Lines per burst: 2\n",
    "# - timestamps (int64): in 12.5 ns units\n",
    "# - stream (uint8): the photon stream according to the mapping {0: DexDem, 1: DexAem, 2: AexDem, 3: AemAem}\n",
    "\"\"\" % filename\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save the data to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fname = '%s_burst_timestamps.csv' % filename.replace('.hdf5', '')\n",
    "dx = ds\n",
    "ich = 0\n",
    "\n",
    "bursts = dx.mburst[ich]\n",
    "timestamps = dx.ph_times_m[ich]\n",
    "stream = (dx.A_ex[ich].view('int8') << 1) + dx.A_em[ich].view('int8')\n",
    "with open(out_fname, 'wt') as f:\n",
    "    f.write(header)\n",
    "    for times, period in zip(bl.iter_bursts_ph(timestamps, bursts),\n",
    "                             bl.iter_bursts_ph(stream, bursts)):\n",
    "        times.tofile(f, sep=',')\n",
    "        f.write('\\n')\n",
    "        period.tofile(f, sep=',')\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the file back\n",
    "\n",
    "For consistency check, we can read back the data we just saved.\n",
    "As an exercise we will put the results in a pandas DataFrame\n",
    "which is more convenient than an array for holding this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start reading the header and computing \n",
    "some file-specific constants. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_fname) as f:\n",
    "    lines = []\n",
    "    lines.append(f.readline())\n",
    "    while lines[-1].startswith('#'):\n",
    "        lines.append(f.readline())\n",
    "    header = ''.join(lines[:-1])\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_map = {0: 'DexDem', 1: 'DexAem', 2: 'AexDem', 3: 'AemAem'}\n",
    "nrows = int(header.split('\\n')[1].split(':')[1].strip())\n",
    "header_len = len(header.split('\\n')) - 1\n",
    "header_len, nrows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a test, we load the data for the first burst into a dataframe, converting the numerical column \"streams\"\n",
    "into photon-stream names (strings). The new column is of type categorical, so it will take very little space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burstph = (pd.read_csv(out_fname, skiprows=header_len, nrows=nrows, header=None).T\n",
    "           .rename(columns={0: 'timestamp', 1: 'stream'}))\n",
    "StreamCategorical = pd.api.types.CategoricalDtype(categories=['DexDem', 'DexAem', 'AexDem', 'AemAem'], ordered=True)\n",
    "burstph.stream = (burstph.stream\n",
    "                  .apply(lambda x: stream_map[pd.to_numeric(x)])\n",
    "                  .astype(StreamCategorical))\n",
    "burstph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reading the whole file I use a different approach. First, I load the entire file \n",
    "in two lists of lists (one for timestamps and one for the stream). Next, I create\n",
    "a single DataFrame with a third column indicating the burst index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from builtins import int  # python 2 workaround, can be removed on python 3\n",
    "\n",
    "# Read data in two list of lists\n",
    "t_list, s_list = [], []\n",
    "with open(out_fname) as f:\n",
    "    for i in range(header_len):\n",
    "        f.readline()\n",
    "    csvreader = csv.reader(f)    \n",
    "    for row in csvreader:\n",
    "        t_list.append([int(v) for v in row])\n",
    "        s_list.append([int(v) for v in next(csvreader)])\n",
    "\n",
    "# Turn the inner list into pandas.DataFrame\n",
    "d_list = []\n",
    "for ib, (t, s) in enumerate(zip(t_list, s_list)):\n",
    "    d_list.append(\n",
    "        pd.DataFrame({'timestamp': t, 'stream': s}, columns=['timestamp', 'stream'])\n",
    "        .assign(iburst=ib)\n",
    "    )\n",
    "\n",
    "# Concatenate dataframes\n",
    "burstph = pd.concat(d_list, ignore_index=True)\n",
    "\n",
    "# Convert stream column into categorical\n",
    "StreamCategorical = pd.api.types.CategoricalDtype(categories=['DexDem', 'DexAem', 'AexDem', 'AemAem'], ordered=True)\n",
    "burstph.stream = (burstph.stream\n",
    "                  .apply(lambda x: stream_map[pd.to_numeric(x)])\n",
    "                  .astype(StreamCategorical))\n",
    "burstph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burstph.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was just an example. There are certainly more efficient ways \n",
    "to read the file into a DataFrame. Please feel free to contribute\n",
    "new methods to illustrate a different (more efficient or simpler)\n",
    "approach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "nav_menu": {},
  "toc": {
   "nav_menu": {
    "height": "174px",
    "width": "252px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "592px",
    "left": "0px",
    "right": "958px",
    "top": "111px",
    "width": "257px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
