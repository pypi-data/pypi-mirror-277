{
 "metadata": {
  "name": "",
  "signature": "sha256:dafa597850652175f81769949fb880d8ecc4cc9f974444a17eca2e3c1956a7fa"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# FRETBursts regression test\n",
      "\n",
      "This notebook implements a simple regression testing for FRETBursts.\n",
      "\n",
      "This notebook defines a series of test-cases that are executed with the current version of FRETBursts. The result of each test is compared with results saved by a previous commit (`compare_commit`). Saving the tests results (by setting `save_reference = True`), is possible to use the current commit as a *compare_commit* in future revisions."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Configuration"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# If True save this run as reference for future comparison\n",
      "save_reference = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Commit to use for test comparison\n",
      "compare_commit = 'f5faeae' # previous saved test point (or None to bootstrap)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run load_fretbursts.py --nogui"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_dir = os.path.abspath(u'../../data/') + '/'\n",
      "data_dir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Comparison functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "test_save_dir = ''\n",
      "if save_reference:\n",
      "    test_save_dir = data_dir + 'test/' + git.get_last_commit() + '/'\n",
      "    if not os.path.exists(test_save_dir):\n",
      "        os.mkdir(test_save_dir)\n",
      "    print 'Saving test results in:', test_save_dir\n",
      "\n",
      "test_load_dir = ''\n",
      "if compare_commit is not None:\n",
      "    test_load_dir = data_dir + 'test/' + compare_commit + '/'\n",
      "    if not os.path.exists(test_load_dir):\n",
      "        raise ValueError('Path %s not found, choose a different commit.' % test_load_dir)\n",
      "    print 'Loading test results from:', test_load_dir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle as pickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "map_ph_sel = {Ph_sel(Dex='Dem'): 'D', Ph_sel(Dex='Aem'): 'A',\n",
      "              Ph_sel('all'): 'DA', Ph_sel(Aex='Aem'): 'AA'}\n",
      "map_renames = dict(leakage='BT', rate_th='Th', leakage_corrected='bt_corrected', dir_ex='dir')\n",
      "new_names = ['bg_fun_name' , 'bg_auto_th', 'bg_ph_sel', 'rate_da', 'bg_da', 'dir_ex', 'dir_ex_corrected']\n",
      "\n",
      "def compare_data(d1, d2, verbose=True, debug=False, exclude_ph_times=False):\n",
      "    \"\"\"Compare two Data() objects for equality (useful for regression test).\n",
      "    \"\"\"\n",
      "    if d2 is None:\n",
      "        print ' * WARNING: Saved test not found, skipping comparison.'\n",
      "        return True\n",
      "        \n",
      "    equal = True\n",
      "    for key in d1:\n",
      "        if verbose: \n",
      "            print \"Testing %s (%s) ... \" % (key, type(d1[key])),\n",
      "            \n",
      "        if callable(d1[key]):\n",
      "            # Skip function comparison\n",
      "            if verbose: print \"skipping (function)\"\n",
      "            continue\n",
      "            \n",
      "        if exclude_ph_times and key == 'ph_times_m':\n",
      "            if verbose: print \"[TEST SKIPPED]\"\n",
      "            continue\n",
      "        \n",
      "        # Detect variable renames or recent additions\n",
      "        if key not in d2:\n",
      "            if key in map_renames and map_renames[key] in d2:\n",
      "                d2[key] = d2[map_renames[key]]\n",
      "            elif key.endswith('_err') or key.startswith('fit_E_') or \\\n",
      "                 key.startswith('bg_th_us') or key in new_names:\n",
      "                print \"WARNING: Attribute '%s' in d1 is missing in d2\" % key\n",
      "                continue\n",
      "            else:    \n",
      "                print \"ERROR\\n * Attribute '%s' in d1 is missing in d2\" % key\n",
      "                equal = False\n",
      "                continue\n",
      "\n",
      "        if d1[key] is None:\n",
      "            if not (d2[key] is None):\n",
      "                equal = False\n",
      "                print \"ERROR\\n * Attribute '%s' is None d1 but %s in d2\" % \\\n",
      "                        (key, d2[key])\n",
      "            elif verbose: \n",
      "                print 'OK (None)'\n",
      "            continue\n",
      "        \n",
      "        # Detect new Ph_sel type and compare to old str representation\n",
      "        if type(d1[key]) is Ph_sel and type(d2[key]) is str:\n",
      "            if map_ph_sel[d1[key]] != d2[key]:\n",
      "                #equal = False\n",
      "                print \"ERROR\\n * Attribute ph_sel does not match: '%s', '%s'\" % \\\n",
      "                        (d1[key], d2[key])\n",
      "                print \"    >>>> Error amended due to bug in old versions.\"\n",
      "            continue\n",
      "            \n",
      "        if type(d1[key]) is Ph_sel and type(d2[key]) is Ph_sel:\n",
      "            equal = d1[key] == d2[key]\n",
      "            if not equal:\n",
      "                print  \"ERROR\\n * Attribute '%s' do not match: '%s', %s\" % \\\n",
      "                        (d1[key], d2[key])\n",
      "            continue\n",
      "                    \n",
      "        # Test if the attributes have the same type\n",
      "        if not (type(d1[key]) == type(d2[key])):\n",
      "            equal = False\n",
      "            print \"ERROR\\n * Attribute '%s' has type %s in d1 but %s in d2\" % (key,\n",
      "                    type(d1[key]), type(d2[key]))\n",
      "            continue\n",
      "        \n",
      "        if np.isscalar(d1[key]):\n",
      "            scalar1, scalar2 = d1[key], d2[key]\n",
      "            if key == 'fname':\n",
      "                scalar1 = os.path.basename(os.path.abspath(scalar1))\n",
      "                scalar2 = os.path.basename(os.path.abspath(scalar2))\n",
      "            if scalar1 != scalar2:\n",
      "                print(\"ERROR\\n d1.{k} and d2.{k} differ (scalar).\".format(k=key))\n",
      "                equal = False\n",
      "            elif verbose: \n",
      "                print 'OK (scalar)'\n",
      "            continue\n",
      "        \n",
      "        # If the attribute is an empty list\n",
      "        if type(d1[key]) is list and len(d1[key]) == 0:\n",
      "            if not (type(d2[key]) is list and len(d2[key]) == 0):\n",
      "                print \"ERROR\\n * Attribute '%s' is an empty list in d1 but not in d2\"\n",
      "                equal = False\n",
      "            elif verbose: \n",
      "                print 'OK (empty list)'\n",
      "            continue\n",
      "        \n",
      "        # If the attribute is a dict\n",
      "        if type(d1[key]) is dict:\n",
      "            dict_comp = []\n",
      "            for sub_key in d1[key]:\n",
      "                if sub_key in d2[key]:\n",
      "                    d2_key_subkey = d2[key][sub_key]\n",
      "                else:\n",
      "                    if sub_key == Ph_sel(Aex='Dem'):\n",
      "                        # Ignore missing key\n",
      "                        print \" * WARNING: Ignoring missing key %s in d2['%s']\" %\\\n",
      "                                (sub_key, key)\n",
      "                        continue\n",
      "                    \n",
      "                    # Try to map new Ph_sel keys to old-style strings\n",
      "                    if type(sub_key) is Ph_sel:\n",
      "                        ph_map = {Ph_sel(Dex='Dem'): 'D', Ph_sel(Dex='Aem'): 'A',\n",
      "                                  Ph_sel('all'): 'DA', Ph_sel(Aex='Aem'): 'AA'}\n",
      "                        d2_key_subkey = d2[key][ph_map[sub_key]]\n",
      "                    else:\n",
      "                        print \"ERROR\\n * The dict '%s' has the key '%s' in d1 but not in d2.\"\n",
      "                        equal = False\n",
      "                        continue\n",
      "                if type(d1[key][sub_key]) == np.ndarray:\n",
      "                    dict_comp.append(np.allclose(d1[key][sub_key], d2_key_subkey))\n",
      "                else:\n",
      "                    dict_comp.append(d1[key][sub_key] == d2[key][sub_key])\n",
      "            equal_dict = np.alltrue(dict_comp)\n",
      "            if not equal_dict:\n",
      "                equal = False\n",
      "                print \"ERROR\\n * Attribute '%s' (dict) differs between d1 and d2\"\n",
      "            elif verbose: \n",
      "                print 'OK (dict)'\n",
      "            continue\n",
      "        \n",
      "        # Detect cases of espected changed values\n",
      "        if key == 'bg_th_us_user':\n",
      "            if not d1['ALEX']:\n",
      "                # Test only the first 3 elemenents: \n",
      "                # other elements, if present, are not significant\n",
      "                d1[key] = d1[key][:3]  \n",
      "                d2[key] = d2[key][:3]\n",
      "            equal = np.array_equal(d1[key], d2[key])\n",
      "            if not equal:\n",
      "                print  \"ERROR\\n * Attribute '%s' does not match: '%s' vs '%s'\" % \\\n",
      "                        (key, d1[key], d2[key])\n",
      "            continue\n",
      "            \n",
      "        # Now the attribute should only be a list of arrays (one per channel)\n",
      "        try:\n",
      "            assert (len(d1[key]) == d1['nch']) and (len(d2[key]) == d2['nch'])\n",
      "        except AssertionError:\n",
      "            equal = False\n",
      "            print \"ERROR\\n * Attribute '%s' has length %d in d1 and length %d in d2.\" % \\\n",
      "                    (key, len(d1[key]), len(d2[key]))\n",
      "            print \"  They should both be nch (%d)\" % d1['nch']\n",
      "            continue\n",
      "\n",
      "        # Test the multi-ch fields (list of arrays)\n",
      "        test_res = np.zeros(d1['nch'], dtype=bool)\n",
      "        for ich, (val1, val2) in enumerate(zip(d1[key], d2[key])):\n",
      "            if type(val1) == type(None):\n",
      "                if debug:\n",
      "                    print ('NA1 {} ({}) {}'.format(key, type(val1), val1))\n",
      "                    print ('NA2 {} ({}) {}'.format(key, type(val2), val2))\n",
      "                test_res[ich] = (val1 == val2)\n",
      "            else:\n",
      "                if debug:\n",
      "                    print ('A1 {} ({}) {}'.format(key, type(val1), val1))\n",
      "                    print ('A2 {} ({}) {}'.format(key, type(val2), val2))\n",
      "                test_res[ich] = np.allclose(val1, val2)\n",
      "                if not test_res[ich] and np.isnan(val1).any():\n",
      "                    print ' * WARNING: Testing only non-NaN values in %s[%d]' % (key, ich)\n",
      "                    test_res[ich] = np.allclose(val1[~np.isnan(val1)], val2[~np.isnan(val1)])\n",
      "        if not test_res.all():\n",
      "            print \"ERROR\\n d1.%s and d2.%s differ (non-scalar).\" % \\\n",
      "                    (key, key)\n",
      "            print \"    Test mask: %s \" % (test_res,)\n",
      "            equal = False\n",
      "        elif verbose: \n",
      "            print 'OK (multi)'\n",
      "        \n",
      "    return equal"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def save_test(name, d, dir_=test_save_dir, exclude_ph_times=True):\n",
      "    print 'Saving test to:', test_save_dir\n",
      "    d_save = dict(d)\n",
      "    \n",
      "    # Remove functions\n",
      "    for key in d:\n",
      "        if callable(d_save[key]):\n",
      "            d_save.pop(key)\n",
      "    \n",
      "    if exclude_ph_times:\n",
      "        d_save.pop('ph_times_m')\n",
      "        \n",
      "    with open(dir_+TEST+'.pickle', 'wb') as f:\n",
      "        pickle.dump(d_save, f, protocol=2)\n",
      "\n",
      "def load_test(name, dir_=test_load_dir):\n",
      "    print 'Loading test from:', test_load_dir\n",
      "    file_name = dir_ + TEST + '.pickle'\n",
      "    if not os.path.isfile(file_name):\n",
      "        print ' - Saved test not found.'\n",
      "        return None\n",
      "    with open(file_name, 'rb') as f:\n",
      "        d2 = pickle.load(f)\n",
      "    return d2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Dataset used for the tests"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fn = \"7d_New_150p_320mW_steer_3.dat\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Find the full file name:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = data_dir + fn\n",
      "fname"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# List of tests"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load and process the data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TEST = 'test1'\n",
      "d = loader.multispot8(fname=fname)\n",
      "d.add(leakage=0.044, gamma=1.)\n",
      "d.calc_bg(bg.exp_fit, time_s=20, tail_min_us=200)\n",
      "d.burst_search_t(L=10, m=10, F=6)\n",
      "d_test = d\n",
      "\n",
      "if save_reference: save_test(TEST, d_test)\n",
      "d_saved = load_test(TEST)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert compare_data(d_test, d_saved, verbose=False, exclude_ph_times=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TEST = 'test2'\n",
      "d.calc_bg(bg.exp_fit, time_s=20, tail_min_us=200)\n",
      "d.burst_search_t(L=10, m=10, P=None, F=6, ph_sel=Ph_sel(Dex='Dem'))\n",
      "d_test = d\n",
      "\n",
      "if save_reference: save_test(TEST, d_test)\n",
      "d_saved = load_test(TEST)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert compare_data(d_test, d_saved, verbose=False, exclude_ph_times=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d_test['ph_sel'], d_saved['ph_sel']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TEST = 'test3'\n",
      "d.calc_bg(bg.exp_fit, time_s=20, tail_min_us=200)\n",
      "d.burst_search_t(L=10, m=10, F=6, ph_sel=Ph_sel(Dex='Aem'))\n",
      "d.fuse_bursts(ms=-1)\n",
      "d_test = d\n",
      "\n",
      "if save_reference: save_test(TEST, d_test)\n",
      "d_saved = load_test(TEST)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert compare_data(d_test, d_saved, verbose=False, exclude_ph_times=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TEST = 'test4'\n",
      "d.calc_bg(bg.exp_fit, time_s=5, tail_min_us=200)\n",
      "d.burst_search_t(L=20, m=10, F=6, ph_sel=Ph_sel('all'))\n",
      "d.fuse_bursts(ms=1)\n",
      "d_test = d\n",
      "\n",
      "if save_reference: save_test(TEST, d_test)\n",
      "d_saved = load_test(TEST)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert compare_data(d_test, d_saved, verbose=False, exclude_ph_times=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TEST = 'test5'\n",
      "\n",
      "E1_raw = 0.65\n",
      "gamma = 0.45\n",
      "d.burst_search_t(L=10, m=10, F=6, ph_sel=Ph_sel(Dex='Aem'))\n",
      "ds = Sel(d, select_bursts.nda, th1=20, gamma1=gamma)\n",
      "ds.update_gamma(1.)\n",
      "ds.fit_E_ML_poiss(E1=E1_raw, method=2)\n",
      "d_test = ds\n",
      "\n",
      "if save_reference: save_test(TEST, d_test)\n",
      "d_saved = load_test(TEST)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert compare_data(d_test, d_saved, verbose=False, exclude_ph_times=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TEST = 'test6'\n",
      "\n",
      "ds.fit_E_generic(E1=E1_raw, fit_fun=bl.gaussian_fit_hist, weights='size', gamma=gamma)\n",
      "d_test = ds\n",
      "\n",
      "if save_reference: save_test(TEST, d_test)\n",
      "d_saved = load_test(TEST)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert compare_data(d_test, d_saved, verbose=False, debug=False, exclude_ph_times=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TEST = 'test7'\n",
      "\n",
      "ds.fit_E_m(E1=E1_raw, weights='size', gamma=gamma)\n",
      "d_test = ds\n",
      "\n",
      "if save_reference: save_test(TEST, d_test)\n",
      "d_saved = load_test(TEST)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert compare_data(d_test, d_saved, verbose=False, exclude_ph_times=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TEST = 'test8'\n",
      "\n",
      "ds.fit_E_m(E1=E1_raw, weights=None, gamma=gamma)\n",
      "d_test = ds\n",
      "\n",
      "if save_reference: save_test(TEST, d_test)\n",
      "d_saved = load_test(TEST)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert compare_data(d_test, d_saved, verbose=False, exclude_ph_times=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# When reference is d1e37 this fails because TEST9 cannot be saved for that reference\n",
      "TEST = 'test9'\n",
      "\n",
      "ds.update_gamma(gamma)\n",
      "ds.fit_E_two_gauss_EM(weights='size', gamma=gamma)\n",
      "d_test = ds\n",
      "\n",
      "if save_reference: save_test(TEST, d_test)\n",
      "d_saved = load_test(TEST)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert compare_data(d_test, d_saved, verbose=False, exclude_ph_times=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TEST = 'test10'\n",
      "\n",
      "ds.fit_E_generic(E1=E1_raw, fit_fun=bl.gaussian_fit_cdf)\n",
      "d_test = ds\n",
      "\n",
      "if save_reference: save_test(TEST, d_test)\n",
      "d_saved = load_test(TEST)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert compare_data(d_test, d_saved, verbose=False, exclude_ph_times=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TEST = 'test11'\n",
      "d.calc_bg(bg.exp_fit, time_s=20, tail_min_us='auto', F_bg=1.7)\n",
      "d.burst_search_t(L=10, m=10, F=6, ph_sel=Ph_sel('all'), max_rate=True)\n",
      "d_test = d\n",
      "\n",
      "if save_reference: save_test(TEST, d_test)\n",
      "d_saved = load_test(TEST)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert compare_data(d_test, d_saved, verbose=False, exclude_ph_times=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TEST = 'test12'\n",
      "d.burst_search_t(L=10, m=10, F=6)\n",
      "ds = Sel(d, select_bursts.size, th1=30)\n",
      "print ds.num_bu()\n",
      "ds.calc_max_rate(m=5, ph_sel=Ph_sel(Dex='Aem'))\n",
      "d_test = ds\n",
      "\n",
      "if save_reference: save_test(TEST, d_test)\n",
      "d_saved = load_test(TEST)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert compare_data(d_test, d_saved, verbose=False, exclude_ph_times=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d_test.stats()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'OK'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}