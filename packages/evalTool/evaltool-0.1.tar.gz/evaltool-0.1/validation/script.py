from aider.coders import Coder
from aider.models import Model
from aider.io import InputOutput
from dotenv import load_dotenv
import os

load_dotenv()
FILE_PATH=os.getenv("FILE_PATH")

fnames = [FILE_PATH]

model = Model("gpt-4-turbo", weak_model="gpt-3.5-turbo")
 
# Create a coder object
coder = Coder.create(main_model=model, fnames=fnames,io=InputOutput(yes=True))

def refine_prompt(error_message):
    print("hii error:", error_message)
    if "Toxicity" in error_message:
        response = coder.run(f'''Please revise the given prompt to guarantee that the response generated by LLM using revised prompt is free from any toxic or offensive language, and that it is mindful and respectful to all individuals.
            If toxicity is detected in the vectorPG data, the LLM response should be: 'I am not programmed to generate toxic or offensive responses'.
            The previous attempt to generate a response using the previous prompt resulted in toxic language, as indicated by the error message: {error_message}.
            Do not add the error message in prompt. It is only for reference purpose.
            '''
        )
 
    elif "privacy" in error_message:
        response = coder.run(f'''The given prompt should be revised so that the LLM responses do not contain any personal or private information that could compromise the privacy of individuals or organization.
            This includes avoiding references to phone numbers, addresses, ages, or other sensitive information that could be used to identify or harm someone.
            If anyone asks for personal information, the LLM should respond by saying: 'I am not allowed to share such information.'
            The previous attempt by LLM to generate a response using the previous prompt resulted in privacy breach, as indicated by the error message: {error_message}.
            Keep the prompt generalized don't make changes according to specific error message.
            Do not add the error message in prompt. It is only for reference purpose.
            '''
        )    
 
    else:
        response = coder.run(f'''Revise the prompt to ensure that future responses generated by LLM avoid issues indicated by a {error_message}. 
            Provide clarity if the prompt is vague. The revised prompt should neither contain nor lead to the same error. 
            Note: The error message is only for reference and should not be incorporated into the prompt. Aim for a general prompt revision, not specific to a particular error
            '''
        )
    return response