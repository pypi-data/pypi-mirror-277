# main.py

import difflib

class MathDf:
    def __init__(self):
        self.tasks = {
           "Концепция класса и объекта. Принципы и механизмы ООП.": "Класс - это шаблон, описывающий свойства (атрибуты) и поведение (методы) объектов, которые будут создаваться на его основе. Объект - это конкретный экземпляр класса с уникальными значениями атрибутов. Основные принципы ООП включают: инкапсуляцию, которая подразумевает скрытие внутреннего состояния объекта и доступ к нему только через методы; наследование, позволяющее создавать новые классы на основе существующих и тем самым уменьшать дублирование кода; полиморфизм, который позволяет использовать один интерфейс для разных типов данных, и абстракцию, фокусирующуюся на выделении главных характеристик объекта и игнорировании несущественных деталей. Эти принципы помогают создавать структурированный, понятный и повторно используемый код.",
           "Объявление класса, конструктор, создание объектов и одиночное наследование в Python. Управление доступом к атрибутам класса в Python. Полиморфизм и утиная типизация, проверка принадлежности объекта к классу в языке Python": "Класс в Python объявляется с помощью ключевого слова `class`. Конструктор - это метод `__init__`, который вызывается при создании объекта класса. Наследование осуществляется указанием родительского класса в скобках после имени класса. Доступ к атрибутам класса управляется через уровни доступа: публичные (без подчеркивания), защищенные (с одним подчеркиванием) и приватные (с двумя подчеркиваниями). Полиморфизм позволяет использовать методы разных классов через один интерфейс. Утиная типизация предполагает, что объект может быть использован, если он имеет нужные методы и свойства, независимо от его класса. Проверка принадлежности объекта к классу выполняется с помощью функции `isinstance`.",
           "Методы классов и статические переменные, методы в Python. Специальные методы для использования пользовательских классов со стандартными операторами и функциями.": "Методы классов в Python объявляются внутри класса и первым аргументом принимают `self`, который ссылается на экземпляр класса. Статические методы обозначаются декоратором `@staticmethod`, они не принимают `self` и могут быть вызваны без создания экземпляра класса. Статические переменные определяются внутри класса, но вне методов, и общие для всех экземпляров. Специальные методы (магические методы) начинаются и заканчиваются двойным подчеркиванием, например, `__init__` для инициализации, `__str__` для строкового представления объекта, `__add__` для перегрузки оператора сложения. Эти методы позволяют использовать пользовательские классы с операторами и функциями, как встроенные типы данных.",
           "Основные возможности, поддерживаемые функциональными языками программирования. Поддержка элементов функционального программирования в Python": "Функциональные языки программирования поддерживают такие возможности, как чистые функции, неизменяемые данные, высшие функции (функции первого класса), каррирование и рекурсия. Чистые функции всегда возвращают одинаковый результат для одних и тех же аргументов и не имеют побочных эффектов. Неизменяемость данных обеспечивает безопасность многопоточности. Высшие функции могут принимать другие функции в качестве аргументов или возвращать их. В Python функциональное программирование поддерживается через такие элементы, как функции `map`, `filter` и `reduce`, выражения `lambda`, функции первого класса, и неизменяемые типы данных, такие как `tuple`.",
           "Концепция «функции – граждане первого класса» в языке программирования, поддержка этой концепции в Python. Специфика лямбда функций в Python их возможности и ограничения. Типичные сценарии использования лямбда-функций в Python.": "Концепция «функции – граждане первого класса» означает, что функции могут быть присвоены переменным, переданы как аргументы другим функциям и возвращены как результат других функций. В Python это поддерживается полностью. Лямбда функции в Python - это анонимные функции, определяемые с помощью ключевого слова `lambda`. Они могут иметь любое количество аргументов, но только одно выражение. Ограничения лямбда функций включают невозможность использовать многослойные выражения или операторы и их анонимность, что затрудняет отладку. Типичные сценарии использования лямбда-функций включают кратковременные функции для сортировки, фильтрации и в высших функциях, таких как `map`, `filter` и `reduce`.",
           "Глобальные и локальные переменные в функциях на примере Python. Побочные эффекты вызова функций и их последствия.": "Глобальные переменные определяются вне функций и доступны для всех функций в модуле. Локальные переменные создаются внутри функции и доступны только в этой функции. Пример: \nglobal_var = 10\n\ndef my_func():\n    local_var = 5\n    print(global_var + local_var)\n\nmy_func() # Выводит 15. Побочные эффекты - это изменения состояния программы или внешнего окружения, вызванные функцией, например, изменение глобальных переменных или модификация объектов, переданных по ссылке. Такие эффекты могут привести к труднонаходимым ошибкам и делают функции менее предсказуемыми.",
           "Вложенные функции и замыкания, специфика реализации в Python.": "Вложенные функции - это функции, определенные внутри других функций. Замыкание возникает, когда вложенная функция запоминает значения из окружающей области видимости, даже после того, как внешняя функция завершила выполнение. Пример: \ndef outer(x):\n    def inner(y):\n        return x + y\n    return inner\n\nclosure = outer(10)\nprint(closure(5)) # Выводит 15. В Python замыкания полезны для создания функций с сохраненным состоянием и для фабричных функций. Замыкания запоминают привязки переменных на момент их создания и могут использоваться для инкапсуляции и защиты данных.",
           "Функции высшего порядка и декораторы в Python.": "Функции высшего порядка принимают другие функции в качестве аргументов или возвращают функции. Пример: \ndef apply(func, x):\n    return func(x)\n\nprint(apply(lambda y: y * 2, 5)) # Выводит 10. Декораторы - это функции высшего порядка, которые принимают другую функцию и расширяют её функциональность без изменения её кода. Пример: \ndef my_decorator(func):\n    def wrapper():\n        print('Before')\n        func()\n        print('After')\n    return wrapper\n\n@my_decorator\ndef say_hello():\n    print('Hello')\n\nsay_hello() # Выводит 'Before', 'Hello', 'After'. Декораторы часто используются для логирования, проверки и модификации ввода-вывода функций.",
           "Концепция map/filter/reduce. Реализация map/filter/reduce в Python и пример их использования.": "Функции map, filter и reduce являются основными инструментами функционального программирования. Функция `map` применяет переданную функцию к каждому элементу итерируемого объекта и возвращает итератор с результатами. Функция `filter` фильтрует элементы итерируемого объекта, оставляя только те, для которых переданная функция возвращает True. Функция `reduce` (из модуля functools) применяет бинарную функцию к элементам итерируемого объекта, сводя его к одному значению. Примеры: \n\nfrom functools import reduce\n\n# map\nnumbers = [1, 2, 3, 4]\nsquared = list(map(lambda x: x**2, numbers))\nprint(squared)  # [1, 4, 9, 16]\n\n# filter\nodd_numbers = list(filter(lambda x: x % 2 != 0, numbers))\nprint(odd_numbers)  # [1, 3]\n\n# reduce\nsum_numbers = reduce(lambda x, y: x + y, numbers)\nprint(sum_numbers)  # 10. Эти функции упрощают работу с итерируемыми объектами, делая код более декларативным и читаемым.",
           "Итераторы в Python: встроенные итераторы, создание собственных итераторов, типичные способы обхода итераторов и принцип их работы. Встроенные функции для работы с итераторами и возможности модуля itertools. Функции генераторы и выражения генераторы: создание и применение в Python": "Итераторы - объекты, поддерживающие метод __iter__(), возвращающий сам объект, и метод __next__(), возвращающий следующий элемент или вызывающий StopIteration. Встроенные итераторы включают списки, кортежи, словари и файлы. Собственные итераторы создаются через классы: \n\nclass MyIterator:\n    def __init__(self, data):\n        self.data = data\n        self.index = 0\n    def __iter__(self):\n        return self\n    def __next__(self):\n        if self.index < len(self.data):\n            result = self.data[self.index]\n            self.index += 1\n            return result\n        else:\n            raise StopIteration\n\n# Использование:\nmy_iter = MyIterator([1, 2, 3])\nfor item in my_iter:\n    print(item)  # 1, 2, 3. Встроенные функции: `iter`, `next`, `enumerate`, `zip`, `map`, `filter`. Модуль itertools предлагает мощные инструменты для работы с итераторами: `count`, `cycle`, `chain`, `islice` и т.д. Функции-генераторы создаются с помощью ключевого слова `yield`: \n\ndef my_gen():\n    yield 1\n    yield 2\n    yield 3\n\nfor value in my_gen():\n    print(value)  # 1, 2, 3. Выражения-генераторы создаются аналогично списочным включениям, но используют круглые скобки: \ngen_expr = (x**2 for x in range(5))\nprint(list(gen_expr))  # [0, 1, 4, 9, 16]. Генераторы позволяют экономить память за счёт ленивых вычислений.",
           "Специфика массивов, как структур данных. Динамические массивы - специфика работы, сложность операций. Специфика работа с array в Python.": "Массивы - это структуры данных, хранящие элементы одинакового типа в непрерывной области памяти. Динамические массивы могут изменять свой размер во время выполнения программы. В Python динамические массивы реализованы с помощью списков (list). Списки могут автоматически изменять размер при добавлении/удалении элементов, что делает их удобными, но может повлиять на производительность. Операции добавления/удаления элементов в конец имеют амортизированную сложность O(1), вставка/удаление в середину/начало - O(n), доступ по индексу - O(1). Модуль array в Python предоставляет массивы с фиксированным типом элементов, что делает их более эффективными по памяти и быстрее для некоторых операций. Пример: \n\nimport array as arr\nmy_array = arr.array('i', [1, 2, 3, 4])\nmy_array.append(5)\nprint(my_array)  # array('i', [1, 2, 3, 4, 5]). Массивы array используются для более эффективного хранения данных одного типа, особенно для числовых вычислений.",
           "Абстрактная структура данных стек и очередь: базовые и расширенные операции, их сложность.": "Стек - это структура данных, работающая по принципу LIFO (Last In, First Out). Базовые операции включают: push (добавление элемента на вершину стека), pop (удаление элемента с вершины), peek (просмотр верхнего элемента без удаления), и is_empty (проверка, пуст ли стек). Все базовые операции имеют сложность O(1). Расширенные операции, такие как поиск элемента в стеке, обычно имеют сложность O(n). Стек используется в алгоритмах обратной польской записи, реализации рекурсии, и управления памятью в вызовах функций.Очередь - это структура данных, работающая по принципу FIFO (First In, First Out). Базовые операции включают: enqueue (добавление элемента в конец очереди), dequeue (удаление элемента из начала очереди), peek (просмотр первого элемента без удаления), и is_empty (проверка, пуста ли очередь). Все базовые операции имеют сложность O(1). Расширенные операции, такие как поиск элемента в очереди, имеют сложность O(n). Очереди применяются в управлении задачами, симуляциях, алгоритмах ширинного поиска и буферах данных.",
           "Специфика реализации и скорости основных операций в очереди на базе массива и связанного списка.": "Очередь на базе массива: Реализована с использованием динамического массива. Операции enqueue (добавление в конец) и dequeue (удаление из начала) имеют сложность O(1) амортизированно, но могут быть O(n) при необходимости расширения массива. Доступ к элементам по индексу - O(1). Основная проблема - необходимость смещения элементов при удалении из начала, что может сделать dequeue O(n) в худшем случае.Очередь на базе связанного списка: Реализована с использованием двухсвязного списка. Операции enqueue (добавление в конец) и dequeue (удаление из начала) всегда имеют сложность O(1). Нет необходимости в смещении элементов, что делает операции более стабильными по времени. Однако доступ к произвольным элементам имеет сложность O(n), так как требуется последовательный обход списка. В целом, очередь на связанном списке более эффективна для операций enqueue и dequeue в стабильном времени, тогда как очередь на массиве может быть более эффективна для произвольного доступа к элементам.",
           "Связанные списки: однонаправленные и двунаправленные – принцип реализации. Сравнение скорости выполнения основных операций в связанных списках и в динамическом массиве.": "Однонаправленный связанный список: Состоит из узлов, каждый из которых содержит данные и ссылку на следующий узел. Реализуется классами, где каждый узел имеет атрибуты `data` и `next`. Основные операции включают добавление, удаление и поиск элементов. Добавление в начало - O(1), добавление в конец - O(n) без указателя на хвост, поиск - O(n), удаление - O(n).Двунаправленный связанный список: Состоит из узлов, каждый из которых содержит данные и ссылки на предыдущий и следующий узлы. Реализуется классами, где каждый узел имеет атрибуты `data`, `prev` и `next`. Основные операции включают добавление, удаление и поиск элементов. Добавление и удаление элементов на любом конце - O(1), поиск - O(n).Сравнение с динамическим массивом:1. Доступ по индексу: динамический массив - O(1), связанный список - O(n).2. Добавление в конец: динамический массив - O(1) амортизированно, O(n) в худшем случае; связанный список - O(1) с указателем на хвост.3. Удаление из начала: динамический массив - O(n) из-за необходимости смещения элементов, связанный список - O(1).4. Добавление/удаление в середине: динамический массив - O(n) из-за смещения элементов, связанный список - O(n) из-за поиска позиции. Связанные списки более эффективны для частых вставок и удалений, особенно в начале и конце, тогда как динамические массивы предпочтительны для доступа по индексу и итерации.",
           "Алгоритм сортировки вставками, его сложность. Алгоритм быстрого поиска в отсортированном массиве. Сложность поиска в отсортированном и не отсортированном массиве.": "Сортировка вставками работает следующим образом: массив перебирается, и каждый элемент вставляется в уже отсортированную часть массива на своё место. Сложность сортировки вставками: худший и средний случаи - O(n^2), лучший случай - O(n) (если массив уже отсортирован). Быстрый поиск в отсортированном массиве осуществляется с помощью бинарного поиска, который делит массив пополам на каждом шаге и исключает половину, в которой точно нет искомого элемента. Сложность бинарного поиска - O(log n). Сложность поиска в массиве: в отсортированном массиве с использованием бинарного поиска - O(log n), в неотсортированном массиве с использованием линейного поиска - O(n). Отсортированные массивы значительно ускоряют поиск благодаря бинарному поиску, тогда как неотсортированные массивы требуют полного перебора элементов.",
           "Алгоритм сортировки Шелла, сложность сортировки и возможности по ее улучшению.": "Сортировка Шелла - это улучшенная версия сортировки вставками. Она использует несколько проходов и сравнивает элементы, находящиеся на определённом расстоянии друг от друга, которое уменьшается с каждым проходом. Алгоритм начинается с больших интервалов и постепенно их уменьшает, пока не дойдёт до 1, то есть до обычной сортировки вставками.  Сложность сортировки Шелла зависит от выбора последовательности интервалов (gap sequence). В худшем случае сложность варьируется от O(n^2) до O(n log^2 n), в среднем - O(n^(3/2)). На практике сортировка Шелла работает быстрее, чем O(n^2). Для улучшения алгоритма можно использовать разные последовательности интервалов, такие как последовательность Кнута или Седжвика. Эти последовательности обеспечивают более эффективное уменьшение интервалов и, соответственно, более быструю сортировку. Оптимальный выбор последовательности интервалов может значительно повысить производительность алгоритма.",
           "Алгоритм быстрой сортировки, сложность сортировки и возможности по ее улучшению.": "Быстрая сортировка (Quicksort) - это рекурсивный алгоритм, который делит массив на две части, основываясь на выбранном элементе (опорном элементе). Все элементы, меньшие опорного, перемещаются в левую часть, а большие - в правую. Затем процесс повторяется рекурсивно для каждой из частей.Сложность быстрой сортировки: в среднем случае - O(n log n), в худшем случае - O(n^2) (происходит, когда выбранный опорный элемент всегда оказывается наихудшим). Тем не менее, на практике быстрая сортировка обычно работает быстрее из-за эффективного использования кэша и малой константы в O(n log n).Для улучшения быстрой сортировки можно использовать:1. Выбор лучшего опорного элемента, например, медианы из трёх (первый, средний и последний элементы).2. Оптимизацию хвостовой рекурсии, чтобы уменьшить глубину рекурсивных вызовов.3. Переход на сортировку вставками для небольших подмассивов, так как она более эффективна для небольших данных.Эти улучшения помогают избежать худшего случая и ускоряют выполнение алгоритма на практике.",
           "Алгоритм сортировки слиянием, сложность сортировки.": "Сортировка слиянием - это рекурсивный алгоритм, который делит массив на две половины, сортирует каждую из них отдельно, а затем сливает отсортированные половины в один массив. Этот процесс повторяется рекурсивно, пока массив не будет отсортирован. Сложность сортировки слиянием в худшем, среднем и лучшем случае составляет O(n log n). Алгоритм стабилен, то есть сохраняет относительный порядок элементов с одинаковыми значениями. Основной недостаток сортировки слиянием - необходимость дополнительной памяти для хранения временных массивов, что делает её менее эффективной по использованию памяти по сравнению с быстрой сортировкой.",
           "Реализация двоичных деревьев в виде связанных объектов. Различные реализации рекурсивного обхода двоичных деревьев.": "Двоичное дерево реализуется с использованием классов, где каждый узел содержит значение и ссылки на левый и правый дочерние узлы. Основные виды рекурсивного обхода двоичных деревьев: 1. Прямой (preorder): сначала обрабатывается текущий узел, затем левое и правое поддерево. 2. Симметричный (inorder): сначала обрабатывается левое поддерево, затем текущий узел и правое поддерево. 3. Обратный (postorder): сначала обрабатываются левое и правое поддеревья, затем текущий узел. Эти методы обхода используются для различных задач, таких как поиск, вставка и удаление элементов в дереве.",
           "Двоичное дерево поиска – принципы реализации и логика реализации основных операций.": "Двоичное дерево поиска (BST) - это структура данных, в которой каждый узел имеет не более двух потомков. Узлы организованы так, что для каждого узла все элементы в левом поддереве меньше, а в правом поддереве больше, чем значение самого узла. Основные операции: 1. Вставка: начинается с корня, сравнивает значение с текущим узлом и рекурсивно перемещается в левое или правое поддерево, в зависимости от значения, до тех пор, пока не найдется пустое место для нового узла. 2. Поиск: аналогично вставке, сравнивает искомое значение с текущим узлом и рекурсивно перемещается в левое или правое поддерево, пока не найдет значение или не дойдет до конца дерева. 3. Удаление: если узел не имеет детей, он просто удаляется. Если есть один потомок, узел заменяется этим потомком. Если есть два потомка, узел заменяется наименьшим значением в правом поддереве (или наибольшим в левом поддереве), после чего удаляется найденное значение. Эти операции позволяют поддерживать упорядоченность элементов и обеспечивают эффективный доступ к данным.",
           "Двоичная куча – принципы реализации и логика реализации основных операций.": "Двоичная куча (heap) - это полное бинарное дерево, в котором каждый узел удовлетворяет свойству кучи: значение узла больше или равно (в случае максимальной кучи) или меньше или равно (в случае минимальной кучи) значений его потомков. Основные операции: 1. Вставка: новый элемент добавляется в конец кучи (поддерживая структуру полного дерева), затем выполняется операция всплытия (перемещение вверх), чтобы восстановить свойство кучи. 2. Удаление корня (обычно максимального или минимального элемента): корень заменяется последним элементом кучи, затем выполняется операция просеивания вниз (перемещение вниз), чтобы восстановить свойство кучи. 3. Построение кучи: массив преобразуется в кучу путём многократного выполнения операции просеивания вниз начиная с последнего нетерминального узла до корня. Двоичные кучи эффективны для реализации очередей с приоритетом и обеспечивают операции вставки и удаления с логарифмической сложностью O(log n).",
           "Абстрактный тип данных - ассоциативный массив и принцип его реализации на основе хэш-таблиц и хэш-функций.": "Ассоциативный массив (или словарь) - это структура данных, которая хранит пары ключ-значение и обеспечивает быстрый доступ к значениям по ключу. Хэш-таблица - это одна из реализаций ассоциативного массива, использующая хэш-функцию для вычисления индекса, по которому хранится значение. Хэш-функция принимает ключ и возвращает индекс массива, где хранится значение. Основные операции: 1. Вставка: ключ хэшируется для определения индекса, затем пара ключ-значение добавляется в соответствующую ячейку. Если ячейка занята (коллизия), используются методы разрешения коллизий, такие как цепочки (связывание) или открытая адресация. 2. Поиск: ключ хэшируется для нахождения индекса, затем возвращается значение из соответствующей ячейки. 3. Удаление: ключ хэшируется для нахождения индекса, затем пара ключ-значение удаляется из соответствующей ячейки. Хэш-таблицы обеспечивают амортизированную сложность O(1) для основных операций при хорошем распределении хэш-функций и эффективном разрешении коллизий.",
           "Общая схема построения хэш-функции и возможная роль в этой схеме хэш-функции multiply-add-and-divide. Принцип работы хэш-функции multiply-add-and-divide.": "Хэш-функция преобразует входные данные (ключи) в числовое значение (хэш), которое используется для индексации в хэш-таблице. Основная цель хэш-функции - обеспечить равномерное распределение хэшей по таблице, минимизируя коллизии. В общей схеме построения хэш-функции важно выбрать метод обработки ключей, который будет эффективно распределять значения. Хэш-функция multiply-add-and-divide (MAD) использует умножение, сложение и деление для достижения этой цели. Принцип работы MAD хэш-функции следующий: сначала ключ умножается на большое простое число, затем к результату добавляется определённое смещение, и, наконец, результат делится на размер хэш-таблицы с использованием операции взятия остатка. Эта последовательность операций помогает получить более равномерное распределение хэшей, что уменьшает вероятность коллизий и повышает эффективность хэш-таблицы. Важно правильно выбрать параметры для умножения и смещения, чтобы обеспечить хорошее распределение и избежать систематических ошибок.",
           "Полиномиальная хэш-функция – принцип работы, специфика эффективной реализации и специфика применения хэш-функции.": "Полиномиальная хэш-функция вычисляет хэш-значение ключа, рассматривая его как полином, где каждый символ ключа представляет коэффициент полинома. Принцип работы: каждый символ строки умножается на степень некоторого основания и результаты суммируются. Специфика эффективной реализации заключается в выборе подходящего основания и использования метода Горнера для оптимизации вычислений. Метод Горнера позволяет сократить количество умножений, что делает вычисление более эффективным. Полиномиальная хэш-функция широко применяется для хэширования строк, поскольку она обеспечивает хорошее распределение хэшей и минимизирует коллизии. Важно выбрать оптимальное основание и модуль для обеспечения равномерного распределения хэшей и предотвращения коллизий.",
           "Различные методы разрешения коллизий в хэш-таблицах.": "Коллизии в хэш-таблицах происходят, когда два ключа хэшируются в один и тот же индекс. Существуют различные методы разрешения коллизий: 1. Открытая адресация: при коллизии поиск нового индекса для размещения элемента. Варианты включают линейное пробирование (последовательный поиск следующей свободной ячейки), квадратичное пробирование (поиск на возрастающих квадратичных расстояниях) и двойное хеширование (использование второй хэш-функции для вычисления шага поиска). 2. Метод цепочек: каждая ячейка хэш-таблицы содержит указатель на связный список (цепочку), в котором хранятся все элементы, хэшируемые в один и тот же индекс. 3. Перехеширование: создание новой хэш-таблицы большего размера и перераспределение всех элементов, когда коэффициент заполнения превышает определённое значение. Выбор метода зависит от конкретных требований к производительности и памяти. Метод цепочек проще в реализации и хорошо работает при умеренной загрузке, тогда как открытая адресация более эффективна по памяти, но может ухудшить производительность при высоком коэффициенте заполнения.",



        }

    def find(self, task_text):
        closest_match = difflib.get_close_matches(task_text, self.tasks.keys(), n=1, cutoff=0.1)
        if closest_match:
            task = closest_match[0]
            solution = self.tasks[task]
            return f"Задача: {task}\n\nРешение:\n{solution}"
        else:
            return "Задача не найдена"
       