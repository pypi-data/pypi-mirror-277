Metadata-Version: 2.1
Name: facebook_simple_scraper
Version: 0.1.12
Summary: A simple scraper for Facebook
Home-page: https://github.com/Eitol/facebook_simple_scraper
Author: Hector Oliveros
Author-email: hector.oliveros.leon@gmail.com
License: MIT
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.12
Description-Content-Type: text/markdown
License-File: LICENCE
Requires-Dist: pydantic~=2.7.1
Requires-Dist: requests~=2.31.0
Requires-Dist: beautifulsoup4~=4.12.3
Requires-Dist: python-dateutil~=2.9.0.post0
Requires-Dist: dateparser~=1.2.0

## Facebook Simple Scraper

Welcome to the Facebook Post Scraper project! Our tool allows you to scrape posts from different Facebook pages, helping you gather crucial information flexibly and efficiently.
 
### üöÄ Features

- Post Scraping: Scrapes individual posts from a Facebook page, capturing all the details that accompany the post.
- Comment Scraping: Fetches the comments under each post. This can provide you with valuable audience feedback and participation related to each post.

 
### üìÑUsage

Using our scraping tool is extremely simple. After setting up your environment correctly, you can start scraping right away!

```python
user, password = "your_user_email", "your_password"
opts = ScraperOptions(
    credentials=[LoginCredentials(
        username=user,
        password=password
    )],
    max_comments_per_post=10,
    sleep_time_min=2,
    sleep_time_max=5,
    stop_conditions=[StopAfterNPosts(5)],
)
scraper = Scraper(opts)
post = scraper.get_posts("NintendoLatAm")
print(list(post))
```
 
üîí License
MIT License (Do whatever you want with this code, but don't blame me if something goes wrong)
 
We hope you find our Facebook Post Scraper helpful! Your feedback and contributions are always welcome. Enjoy scraping!

 
The Facebook Post Scraper Team
‚ùó Disclaimers: Please be aware of Facebook's terms and conditions pertaining to data scraping. It's your responsibility to use this tool in accordance with those terms.
